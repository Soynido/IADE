# ğŸ¤– SystÃ¨me de GÃ©nÃ©ration IA de Questions MÃ©dicales IADE

## ğŸ¯ Objectif

Ce systÃ¨me permet de gÃ©nÃ©rer automatiquement des QCM et cas cliniques mÃ©dicaux de niveau IADE Ã  partir des cours extraits, **100% en local, sans API externe**.

## ğŸ“¦ PrÃ©requis

### SystÃ¨me

- **Python** : 3.9+
- **Node.js** : 20+
- **Ollama** : derniÃ¨re version
- **Tesseract** : 5.0+ (pour OCR)
- **Espace disque** : ~10GB (modÃ¨les Ollama)
- **RAM** : 8GB minimum (16GB recommandÃ©)
- **GPU** : optionnel (accÃ©lÃ¨re x5-10 la gÃ©nÃ©ration)

### Installation des outils

#### 1. Installer Ollama

```bash
# macOS/Linux
curl -fsSL https://ollama.com/install.sh | sh

# Ou tÃ©lÃ©charger depuis https://ollama.com
```

#### 2. TÃ©lÃ©charger un modÃ¨le mÃ©dical

```bash
# Option 1 : Meditron-7B (EPFL, spÃ©cialisÃ© mÃ©dical) - RECOMMANDÃ‰
ollama pull meditron

# Option 2 : BioMistral-7B (alternative franÃ§aise pharma)
ollama pull biomistral

# Option 3 : Mistral 7B Instruct (fallback gÃ©nÃ©raliste FR)
ollama pull mistral
```

#### 3. Installer Tesseract OCR (macOS)

```bash
brew install tesseract tesseract-lang
```

#### 4. CrÃ©er environnement Python

```bash
cd "/Users/valentingaludec/IADE /iade-app"
python3 -m venv venv
source venv/bin/activate  # ou venv\Scripts\activate sur Windows
pip install -r scripts/extraction/requirements.txt
```

## ğŸš€ Utilisation

### Pipeline complet automatique

```bash
npm run ai:full-pipeline
```

Cette commande exÃ©cute :
1. Construction du Ground Truth depuis les donnÃ©es existantes
2. GÃ©nÃ©ration de 50 questions via Ollama/Meditron
3. Validation automatique (embeddings sÃ©mantiques)
4. Fusion dans `compiledQuestions.json`
5. Recompilation de l'app

### Ã‰tapes individuelles

#### 1. Extraire les PDFs (optionnel)

Si vous voulez rÃ©extraire les PDFs depuis zÃ©ro :

```bash
npm run extract:full
```

#### 2. Construire le Ground Truth

```bash
npm run build:groundtruth
```

CrÃ©e `src/data/groundTruth.json` avec les concepts extraits.

#### 3. GÃ©nÃ©rer des questions via IA

```bash
npm run ai:generate
# Ou avec un nombre spÃ©cifique :
python scripts/ai_generation/generate_batch.py 100
```

GÃ©nÃ¨re des questions dans `src/data/questions-generated.json`.

#### 4. Valider les questions

```bash
npm run ai:validate
```

Valide les questions et crÃ©e `src/data/questions-validated.json`.

#### 5. Fusionner dans l'app

```bash
npm run ai:merge
```

Fusionne les questions validÃ©es dans `compiledQuestions.json`.

#### 6. Lancer l'app

```bash
npm run dev
```

## ğŸ“Š MÃ©triques de QualitÃ©

### Validation automatique

Chaque question est validÃ©e selon 4 critÃ¨res :

1. **SimilaritÃ© sÃ©mantique** (40%) : > 0.70 avec le contexte source
2. **Couverture keywords** (25%) : PrÃ©sence des mots-clÃ©s du concept
3. **QualitÃ© des choix** (20%) : 4 choix, 1 seule bonne rÃ©ponse, pas de doublons
4. **Format** (15%) : Question se termine par ?, explications complÃ¨tes

**Seuil d'acceptation** : Score global â‰¥ 0.75

### RÃ©sultats attendus

- âœ… Taux d'acceptation automatique : > 60%
- âœ… SimilaritÃ© sÃ©mantique moyenne : > 0.75
- âœ… Taux de bullshit : < 10%
- âœ… Mix : 70% QCM, 30% Cas Cliniques

## ğŸ§ª Exemple de sortie

### Question gÃ©nÃ©rÃ©e

```json
{
  "id": "ai_gen_1",
  "question": "Quels sont les signes typiques d'un surdosage morphinique ?",
  "choices": [
    "Mydriase et tachycardie",
    "BradypnÃ©e et myosis",
    "Hyperthermie et agitation",
    "TachypnÃ©e et confusion"
  ],
  "correct": "BradypnÃ©e et myosis",
  "explanation": "Le surdosage morphinique se caractÃ©rise par une dÃ©pression respiratoire (bradypnÃ©e), un myosis (pupilles en tÃªte d'Ã©pingle) et une altÃ©ration de la conscience. Le traitement repose sur l'administration de naloxone.",
  "source": "ai-generated",
  "generator": "ollama-meditron",
  "domain": "Pharmacologie",
  "validation": {
    "overall_score": 0.87,
    "scores": {
      "semantic_similarity": 0.92,
      "keywords_coverage": 0.80,
      "choices_quality": 1.0,
      "format_quality": 1.0
    }
  }
}
```

## ğŸ”§ Configuration avancÃ©e

### Changer le modÃ¨le

Modifiez `scripts/ai_generation/ollama_client.py` :

```python
client = OllamaClient(model="biomistral")  # ou "mistral"
```

### Ajuster le seuil de validation

Modifiez `scripts/ai_generation/question_validator.py` :

```python
return {
    "valid": overall_score >= 0.80,  # Augmenter Ã  0.80 pour plus de rigueur
    ...
}
```

### GÃ©nÃ©rer uniquement des QCM (pas de cas cliniques)

Modifiez `scripts/ai_generation/generate_batch.py` :

```python
# Ligne 627
question_type = "qcm"  # Toujours QCM
```

## ğŸ“ Structure des fichiers

```
iade-app/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ extraction/
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â”œâ”€â”€ extractWithUnstructured.py
â”‚   â”‚   â”œâ”€â”€ extractWithPyMuPDF.py
â”‚   â”‚   â”œâ”€â”€ mergeExtractions.py
â”‚   â”‚   â””â”€â”€ runFullExtraction.sh
â”‚   â”œâ”€â”€ ai_generation/
â”‚   â”‚   â”œâ”€â”€ ollama_client.py
â”‚   â”‚   â”œâ”€â”€ prompt_builder.py
â”‚   â”‚   â”œâ”€â”€ generate_batch.py
â”‚   â”‚   â”œâ”€â”€ embedding_service.py
â”‚   â”‚   â”œâ”€â”€ question_validator.py
â”‚   â”‚   â””â”€â”€ validate_batch.py
â”‚   â”œâ”€â”€ buildGroundTruth.ts
â”‚   â””â”€â”€ mergeValidatedQuestions.ts
â”œâ”€â”€ src/
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ groundTruth.json (gÃ©nÃ©rÃ©)
â”‚       â”œâ”€â”€ questions-generated.json (gÃ©nÃ©rÃ©)
â”‚       â”œâ”€â”€ questions-validated.json (gÃ©nÃ©rÃ©)
â”‚       â””â”€â”€ compiledQuestions.json (mis Ã  jour)
```

## ğŸ› DÃ©pannage

### Ollama ne rÃ©pond pas

```bash
# VÃ©rifier qu'Ollama tourne
ollama list

# RedÃ©marrer Ollama
ollama serve
```

### Erreur Python "module not found"

```bash
# RÃ©activer le venv
source venv/bin/activate
pip install -r scripts/extraction/requirements.txt
```

### Questions gÃ©nÃ©rÃ©es incohÃ©rentes

1. Augmenter le seuil de validation Ã  0.80
2. Utiliser Meditron au lieu de Mistral
3. Enrichir le Ground Truth avec plus de contexte

### GÃ©nÃ©ration trop lente

- Installer avec GPU si disponible
- RÃ©duire le nombre de questions : `npm run ai:generate 20`
- Utiliser un modÃ¨le plus petit : `ollama pull mistral:7b-instruct`

## ğŸ“Š Logs et monitoring

Les logs dÃ©taillÃ©s sont affichÃ©s dans la console lors de :
- `npm run ai:generate` : Stats de gÃ©nÃ©ration
- `npm run ai:validate` : Scores de validation
- `npm run ai:merge` : Nombre de questions ajoutÃ©es

## ğŸ¯ Prochaines Ã©tapes

1. âœ… Pipeline complet opÃ©rationnel
2. ğŸš§ AmÃ©lioration du Ground Truth (extraction PDF avancÃ©e)
3. ğŸš§ Interface de rÃ©vision manuelle des questions
4. ğŸš§ A/B testing qualitÃ© (IA vs humaines)
5. ğŸš§ Dashboard mÃ©triques IA dans l'app

## ğŸ“„ Licence

MIT License - Open Source

---

**ğŸ¤– SystÃ¨me de gÃ©nÃ©ration IA 100% local et gratuit pour l'excellence mÃ©dicale IADE**

