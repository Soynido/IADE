# ğŸš€ Installation Rapide - SystÃ¨me IA IADE

## Ã‰tape 1 : Installer Ollama

```bash
# macOS/Linux
curl -fsSL https://ollama.com/install.sh | sh

# Ou tÃ©lÃ©charger depuis https://ollama.com
```

## Ã‰tape 2 : TÃ©lÃ©charger le modÃ¨le mÃ©dical

```bash
# Meditron-7B (recommandÃ© pour IADE)
ollama pull meditron
```

**â±ï¸ Temps de tÃ©lÃ©chargement** : ~5 minutes (modÃ¨le ~4GB)

## Ã‰tape 3 : Tester Ollama

```bash
ollama run meditron "Quels sont les signes d'un surdosage morphinique ?"
```

Si une rÃ©ponse mÃ©dicale s'affiche, âœ… Ollama fonctionne !

## Ã‰tape 4 : Installer les dÃ©pendances Python

```bash
cd "/Users/valentingaludec/IADE /iade-app"

# CrÃ©er environnement virtuel
python3 -m venv venv
source venv/bin/activate

# Installer les packages
pip install -r scripts/extraction/requirements.txt
```

**â±ï¸ Temps d'installation** : ~3-5 minutes

## Ã‰tape 5 : Installer Tesseract (optionnel, pour OCR)

```bash
# macOS
brew install tesseract tesseract-lang
```

## Ã‰tape 6 : GÃ©nÃ©rer des questions IA

### Option A : Pipeline complet automatique (recommandÃ©)

```bash
npm run ai:full-pipeline
```

Cette commande :
1. âœ… CrÃ©e le Ground Truth depuis vos donnÃ©es existantes
2. âœ… GÃ©nÃ¨re 50 questions via Meditron
3. âœ… Valide automatiquement (score â‰¥ 0.75)
4. âœ… Fusionne dans compiledQuestions.json
5. âœ… Recompile l'app

**â±ï¸ Temps total** : ~30-60 minutes (dÃ©pend du CPU/GPU)

### Option B : Ã‰tapes manuelles

```bash
# 1. CrÃ©er le Ground Truth
npm run build:groundtruth

# 2. GÃ©nÃ©rer questions (50 par dÃ©faut)
npm run ai:generate

# 3. Valider
npm run ai:validate

# 4. Fusionner dans l'app
npm run ai:merge

# 5. Recompiler
npm run compile
```

## Ã‰tape 7 : Lancer l'app

```bash
npm run dev
```

Ouvrez http://localhost:5173

Les questions IA sont marquÃ©es avec un badge **ğŸ¤– IA** violet.

---

## ğŸ¯ RÃ©sultats attendus

AprÃ¨s gÃ©nÃ©ration complÃ¨te :
- âœ… ~30-40 questions IA validÃ©es ajoutÃ©es
- âœ… Score de qualitÃ© moyen : > 0.80
- âœ… Mix : 70% QCM, 30% Cas Cliniques
- âœ… Badge ğŸ¤– IA visible sur les questions gÃ©nÃ©rÃ©es

---

## âš¡ AccÃ©lÃ©rer la gÃ©nÃ©ration

### Avec GPU (si disponible)

La gÃ©nÃ©ration sera ~5-10x plus rapide automatiquement.

### GÃ©nÃ©rer moins de questions

```bash
# Seulement 20 questions
python scripts/ai_generation/generate_batch.py 20
```

### Utiliser un modÃ¨le plus petit

```bash
ollama pull mistral:7b-instruct
```

Puis modifiez `scripts/ai_generation/ollama_client.py` :
```python
self.model = "mistral:7b-instruct"
```

---

## ğŸ› ProblÃ¨mes courants

### "ollama: command not found"

```bash
# VÃ©rifier l'installation
which ollama

# RÃ©installer si nÃ©cessaire
curl -fsSL https://ollama.com/install.sh | sh
```

### "No module named 'sentence_transformers'"

```bash
source venv/bin/activate
pip install sentence-transformers
```

### Questions gÃ©nÃ©rÃ©es incohÃ©rentes

1. Augmenter le seuil de validation dans `question_validator.py` :
```python
return {"valid": overall_score >= 0.85, ...}
```

2. Utiliser Meditron au lieu de Mistral gÃ©nÃ©rique

---

## ğŸ“Š VÃ©rifier les rÃ©sultats

### Nombre de questions IA ajoutÃ©es

```bash
grep -c "ai-generated" src/data/compiledQuestions.json
```

### Score moyen de validation

AffichÃ© dans les logs lors de `npm run ai:validate`

---

## ğŸ“ Documentation complÃ¨te

Voir `README_AI_GENERATION.md` pour :
- Configuration avancÃ©e
- DÃ©pannage dÃ©taillÃ©
- Personnalisation des prompts
- MÃ©triques de qualitÃ©

---

**âœ¨ FÃ©licitations ! Votre systÃ¨me de gÃ©nÃ©ration IA est opÃ©rationnel.**

ğŸ”— **Prochaine Ã©tape** : Lancer `npm run ai:full-pipeline` et attendre les rÃ©sultats !

