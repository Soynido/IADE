# üß© Pipeline Q/A Complet - Guide d'utilisation

## üìã Vue d'ensemble

Ce document d√©crit le **pipeline complet de gestion des questions/r√©ponses** impl√©ment√© pour le projet EQOW IADE. Le pipeline permet d'extraire, aligner, valider et fusionner les paires Question/R√©ponse depuis les annales PDF vers le syst√®me de g√©n√©ration IA.

---

## üéØ Objectifs

Le pipeline g√®re d√©sormais les r√©ponses √† **tous les niveaux** :

| √âtape | Gestion des R√©ponses | D√©tails |
|-------|---------------------|---------|
| **Extraction OCR** | ‚úÖ Oui | D√©tection intelligente des blocs QUESTIONS/R√âPONSES |
| **Alignement Q‚ÜîR** | ‚úÖ Oui | Association automatique question ‚Üí r√©ponse |
| **Fusion GroundTruth** | ‚úÖ Oui | Enrichissement des concepts avec paires Q/A r√©elles |
| **G√©n√©ration IA** | ‚úÖ Oui | Mod√®le produit question + r√©ponse + explication |
| **Validation IA** | ‚úÖ Oui | Validation s√©mantique bilat√©rale Q+R+coh√©rence |

---

## üõ†Ô∏è Scripts cr√©√©s

### 1. `alignQuestionsAnswers.ts`

**R√¥le** : D√©tection et alignement intelligent des blocs QUESTIONS/R√âPONSES dans les PDFs OCR.

**Fonctionnalit√©s** :
- D√©tection robuste des blocs "QUESTIONS DE X √Ä Y" et "R√âPONSES DE X √Ä Y"
- Normalisation OCR avanc√©e (gestion de "I" vs "1", "2O" vs "20", etc.)
- Parsing intelligent par num√©ros de questions
- Validation de coh√©rence et statistiques de couverture

**Utilisation** :
```bash
cd iade-app
npx tsx scripts/pipelines/alignQuestionsAnswers.ts
```

**Sortie** : `src/data/concours/annales-aligned.json`

---

### 2. `improveAlignmentFromRaw.ts`

**R√¥le** : Am√©lioration de l'alignement Q/A depuis les fichiers `*-raw.json` existants.

**Fonctionnalit√©s** :
- Lecture des fichiers `annalescorrig√©es-Volume-X-raw.json`
- Extraction des r√©ponses depuis les fichiers OCR bruts
- D√©coupage intelligent sur les marqueurs de r√©ponses (@, ¬©, ¬Æ, I), etc.)
- Calcul de confiance (high/medium/low) par r√©ponse

**Utilisation** :
```bash
cd iade-app
npx tsx scripts/pipelines/improveAlignmentFromRaw.ts
```

**Sortie** : `src/data/concours/annales-aligned.json`

**Statistiques obtenues** :
- 10 questions extraites
- 7 r√©ponses align√©es (70% de couverture)
- 6 avec confiance haute, 1 moyenne

---

### 3. `mergeToGroundTruth.ts`

**R√¥le** : Fusion intelligente des paires Q/A dans `groundTruth.json`.

**Fonctionnalit√©s** :
- Matching automatique Q/A ‚Üí Concepts existants (par mots-cl√©s et contexte)
- Cr√©ation de nouveaux concepts pour les Q/A orphelines
- Enrichissement avec champ `qa_pairs` contenant les paires r√©elles
- Sauvegarde automatique (`groundTruth.backup.json`)

**Utilisation** :
```bash
cd iade-app
npx tsx scripts/pipelines/mergeToGroundTruth.ts
```

**R√©sultats** :
- 2 concepts existants enrichis
- 8 nouveaux concepts cr√©√©s
- Total : 58 concepts dans `groundTruth.json`

---

### 4. `question_validator.py` (modifi√©)

**R√¥le** : Validation s√©mantique bilat√©rale Question + R√©ponse.

**Nouvelles fonctionnalit√©s** :
- **Param√®tre `with_answers`** : Active la validation Q+R
- **3 scores s√©mantiques** :
  - `semantic_similarity_q` : Question vs Concept
  - `semantic_similarity_a` : R√©ponse/Explication vs Concept
  - `q_to_a_coherence` : Coh√©rence Question ‚Üî R√©ponse
- **Pond√©ration adaptative** : Poids ajust√©s selon le mode avec/sans r√©ponses

**Scores de validation** :

#### Mode standard (sans `--with-answers`) :
```python
overall_score = (
    semantic_similarity_q * 0.40 +
    keywords_coverage * 0.25 +
    choices_quality * 0.20 +
    format_quality * 0.15
)
```

#### Mode avec `--with-answers` :
```python
overall_score = (
    semantic_similarity_q * 0.25 +
    semantic_similarity_a * 0.25 +
    q_to_a_coherence * 0.15 +
    keywords_coverage * 0.15 +
    choices_quality * 0.10 +
    format_quality * 0.10
)
```

---

### 5. `validate_batch.py` (modifi√©)

**R√¥le** : Validation de batch avec support du flag `--with-answers`.

**Nouvelles options CLI** :
```bash
cd iade-app
python scripts/ai_generation/validate_batch.py --help
```

**Arguments** :
- `--generated` : Chemin questions g√©n√©r√©es (d√©faut: `src/data/questions-generated.json`)
- `--ground-truth` : Chemin groundTruth (d√©faut: `src/data/groundTruth.json`)
- `--output` : Chemin sortie valid√©es (d√©faut: `src/data/questions-validated.json`)
- `--with-answers` : Active validation Q+R (d√©faut: d√©sactiv√©)

**Exemples d'utilisation** :

```bash
# Validation standard (questions uniquement)
python scripts/ai_generation/validate_batch.py

# Validation compl√®te avec r√©ponses
python scripts/ai_generation/validate_batch.py --with-answers

# Validation personnalis√©e
python scripts/ai_generation/validate_batch.py \
  --generated src/data/my-questions.json \
  --ground-truth src/data/groundTruth.json \
  --output src/data/my-validated.json \
  --with-answers
```

**Sortie avec `--with-answers`** :
```
[1] ‚úÖ Score: 0.82 | Q:0.75 A:0.68 Q‚ÜîA:0.55
[2] ‚ùå Score: 0.62 | Q:0.72 A:0.48 Q‚ÜîA:0.43
      ‚ö†Ô∏è Similarit√© r√©ponse trop faible: 0.48 < 0.55
      ‚ö†Ô∏è Coh√©rence Q‚ÜîA faible: 0.43 < 0.50

üìä R√âSULTATS VALIDATION (avec validation Q+R)
  Total: 30
  Accept√©es: 22 (73.3%)
  Rejet√©es: 8 (26.7%)
  Score moyen: 0.78

  üìà SCORES D√âTAILL√âS (avec --with-answers)
  Similarit√© Q moyenne: 0.72
  Similarit√© A moyenne: 0.65
  Coh√©rence Q‚ÜîA moyenne: 0.58

  üíæ Fichier: src/data/questions-validated.json
```

---

## üìä Fichiers g√©n√©r√©s

### `annales-aligned.json`

Structure :
```json
{
  "metadata": {
    "generatedAt": "2025-11-04T10:42:20.014Z",
    "totalQuestions": 10,
    "withAnswer": 7,
    "coverageRate": "70.0%"
  },
  "questions": [
    {
      "id": "Volume-1-1",
      "questionNumber": 1,
      "question": "D√©finissez le score de Glasgow...",
      "answer": "Le score de Glasgow est un score universel...",
      "confidence": "high",
      "source": "Volume-1"
    }
  ],
  "questionsWithoutAnswers": [...]
}
```

### `groundTruth.json` (enrichi)

Nouveaux champs dans chaque concept :
```json
{
  "id": "c1",
  "concept": "Morphine palier III",
  "domain": "Pharmacologie",
  "keywords": ["morphine", "analg√©sie"],
  "context": "...",
  "qa_pairs": [
    {
      "questionNumber": 5,
      "question": "Quels sont les signes de surdosage morphinique?",
      "answer": "Bradypn√©e, myosis, troubles de conscience. Naloxone IV.",
      "confidence": "high",
      "source": "Volume-1"
    }
  ]
}
```

---

## üîç Validation S√©mantique - D√©tails Techniques

### Mod√®le d'embeddings

Le syst√®me utilise `SentenceTransformers` avec des mod√®les m√©dicaux :
1. **BioBERT** (`dmis-lab/biobert-base-cased-v1.2`) - Priorit√© 1
2. **PubMedBERT** (`microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext`)
3. **SciBERT** (`allenai/scibert_scivocab_uncased`)
4. **Fallback** : `all-MiniLM-L6-v2`

### Seuils de validation

| M√©trique | Seuil | Description |
|----------|-------|-------------|
| `semantic_similarity_q` | 0.60 | Question vs Concept |
| `semantic_similarity_a` | 0.55 | R√©ponse vs Concept (plus tol√©rant) |
| `q_to_a_coherence` | 0.50 | Coh√©rence interne Q‚ÜîR |
| `overall_score` | 0.75 | Score global pour validation |

### Calcul de similarit√©

```python
def cosine_similarity(emb1, emb2):
    return float(np.dot(emb1, emb2))  # Embeddings normalis√©s
```

---

## üöÄ Workflow complet

### √âtape 1 : Extraction et alignement

```bash
cd iade-app

# Extraire et aligner les Q/A depuis les PDFs
npx tsx scripts/pipelines/improveAlignmentFromRaw.ts
```

**Output** : `annales-aligned.json` (10 Q/A, 70% avec r√©ponse)

### √âtape 2 : Fusion dans groundTruth

```bash
# Enrichir groundTruth.json avec les paires Q/A
npx tsx scripts/pipelines/mergeToGroundTruth.ts
```

**Output** : `groundTruth.json` enrichi (58 concepts, dont 8 nouveaux)

### √âtape 3 : G√©n√©ration IA (existant)

```bash
# G√©n√©rer des questions avec Mistral/Ollama
python scripts/ai_generation/generate_batch.py
```

**Output** : `questions-generated.json`

### √âtape 4 : Validation avec r√©ponses

```bash
# Valider avec scores Q+R+coh√©rence
python scripts/ai_generation/validate_batch.py --with-answers
```

**Output** : `questions-validated.json` + statistiques d√©taill√©es

---

## üìà Am√©liorations Futures

### Court terme

- [ ] Am√©liorer le parsing OCR (actuellement 70% de couverture)
- [ ] Ajouter support pour Volume-2 des annales
- [ ] Cr√©er un script de visualisation des scores s√©mantiques

### Moyen terme

- [ ] Fine-tuning du mod√®le d'embeddings sur corpus m√©dical IADE
- [ ] D√©tection automatique des concepts manquants dans groundTruth
- [ ] Export des Q/A valid√©es vers format Anki/Quizlet

### Long terme

- [ ] RLHF (Reinforcement Learning from Human Feedback) sur les Q/A
- [ ] G√©n√©ration de variantes de questions par paraphrasage contr√¥l√©
- [ ] Int√©gration avec syst√®me de spaced repetition adaptatif

---

## üêõ Troubleshooting

### Probl√®me : Aucune r√©ponse extraite

**Cause** : OCR de mauvaise qualit√© ou format PDF inhabituel

**Solution** :
1. V√©rifier le contenu du fichier `tmp/ocr-cache/*.txt`
2. Ajuster les regex dans `improveAlignmentFromRaw.ts`
3. Tester avec un sous-ensemble manuel

### Probl√®me : Scores s√©mantiques trop bas

**Cause** : Mod√®le d'embeddings non m√©dical ou concepts trop g√©n√©riques

**Solution** :
1. V√©rifier que BioBERT ou PubMedBERT est charg√©
2. Enrichir le champ `context` dans groundTruth.json
3. Ajouter plus de keywords m√©dicaux sp√©cifiques

### Probl√®me : Validation √©choue avec `--with-answers`

**Cause** : Questions g√©n√©r√©es sans champ `explanation` ou vide

**Solution** :
1. V√©rifier que le prompt de g√©n√©ration inclut l'explication
2. Ajuster les seuils dans `question_validator.py` (lignes 40, 51)
3. Utiliser le mode standard sans `--with-answers` temporairement

---

## üìö R√©f√©rences

- **Repo GitHub** : (√† compl√©ter)
- **Documentation SentenceTransformers** : https://www.sbert.net/
- **BioBERT Paper** : Lee et al., 2020
- **Spec projet EQOW** : `spec.md`, `plan.md`, `tasks.md`

---

## ‚úÖ Checklist de validation

Avant de pousser en production, v√©rifier que :

- [ ] `annales-aligned.json` contient au moins 50 Q/A avec `confidence: "high"`
- [ ] `groundTruth.json` a une sauvegarde r√©cente (`groundTruth.backup.json`)
- [ ] `validate_batch.py --with-answers` fonctionne sans erreur
- [ ] Les scores moyens Q, A et Q‚ÜîA sont > 0.60
- [ ] Aucun linter error dans TypeScript et Python
- [ ] `tasks.md` est √† jour avec les nouvelles t√¢ches 1.8.x

---

**Date de cr√©ation** : 4 novembre 2025  
**Auteur** : Pipeline automatis√© EQOW  
**Version** : 1.0.0

---

üéâ **Pipeline Q/A complet op√©rationnel !**

